# HDFS: 분산 파일시스템 구조

Hadoop Distributed File System(HDFS)은 대용량 데이터를 분산 환경에서 저장하고 처리하기 위해 설계된 파일시스템입니다. HDFS는 고가용성, 내결함성, 수평적 확장성을 목표로 하며, 대규모 데이터 분석 및 빅데이터 처리에 적합한 인프라를 제공합니다.

---

## 1. HDFS의 기본 개념

### 1.1. 분산 파일시스템의 필요성

- **대용량 데이터 처리:**  
  전통적인 파일시스템은 단일 서버의 한계를 극복하기 어려우므로, 수 페타바이트(PB) 이상의 데이터를 여러 서버에 분산 저장할 필요가 있습니다.
- **높은 확장성 및 내결함성:**  
  노드 장애가 발생해도 데이터 손실 없이 서비스를 지속할 수 있도록, 데이터를 여러 노드에 복제하고, 자동 장애 복구를 지원합니다.
- **병렬 처리 지원:**  
  분산 저장된 데이터를 여러 노드에서 병렬로 처리함으로써, 대규모 데이터 분석 및 처리 작업의 성능을 극대화합니다.

### 1.2. HDFS의 기본 원칙

- **Write Once, Read Many (WORM):**  
  HDFS는 주로 데이터 배치 처리와 로그 저장처럼 한 번 기록한 데이터를 여러 번 읽는 워크로드에 최적화되어 있습니다.
- **고장 허용 설계:**  
  단일 장애점(Single Point of Failure, SPOF)을 최소화하고, 노드 장애 시에도 데이터 접근이 가능하도록 설계되었습니다.
- **데이터 블록 기반 저장:**  
  파일은 고정 크기의 블록(기본값 128MB 또는 256MB 등)으로 분할되어 각 블록이 여러 DataNode에 분산 저장됩니다.

---

## 2. HDFS 아키텍처 구성 요소

HDFS는 크게 두 가지 주요 구성 요소로 나뉩니다.

### 2.1. NameNode

- **역할:**  
  - HDFS의 메타데이터(파일 이름, 디렉터리 구조, 블록 위치, 권한 등)를 관리합니다.  
  - 클라이언트의 파일 시스템 요청(파일 생성, 삭제, 읽기 요청 등)을 처리하고, DataNode에 저장된 블록 정보를 제공합니다.
  
- **특징:**  
  - 단일 NameNode가 클러스터의 중앙 메타데이터 저장소 역할을 하므로, 고가용성을 위해 보조 NameNode(Secondary NameNode 또는 Standby NameNode) 구성이 필요합니다.
  - 메모리 내에 모든 메타데이터를 유지하므로, 메타데이터 양이 매우 많아질 경우 메모리 요구사항이 증가합니다.

### 2.2. DataNode

- **역할:**  
  - 실제 데이터 블록을 저장하는 워커 노드입니다.  
  - NameNode의 명령에 따라 블록을 생성, 삭제, 복제하며, 클라이언트의 읽기/쓰기 요청을 처리합니다.
  
- **특징:**  
  - 각 DataNode는 주기적으로 NameNode에 자신의 상태와 보유한 블록 정보를 보고합니다.
  - 데이터 블록이 여러 DataNode에 복제되어 저장되므로, 한 노드에 장애가 발생하더라도 데이터 접근이 가능합니다.

---

## 3. 데이터 저장 및 복제 메커니즘

### 3.1. 데이터 블록 저장

- **블록 분할:**  
  파일은 HDFS에 저장될 때 일정한 크기의 블록으로 분할됩니다.  
  - 예를 들어, 1GB 파일을 128MB 블록 크기로 분할하면 약 8개의 블록으로 나뉩니다.
  
- **메타데이터 관리:**  
  NameNode는 각 파일의 블록 목록, 각 블록의 위치(어느 DataNode에 저장되었는지) 등을 관리합니다.

### 3.2. 복제 전략

- **복제 팩터(Replication Factor):**  
  각 데이터 블록은 설정된 복제 팩터만큼 여러 DataNode에 저장됩니다. 기본 복제 팩터는 보통 3으로 설정됩니다.
  
- **복제 배치:**  
  - **데이터 내구성 및 가용성 보장:** 복제된 블록은 한 DataNode가 장애를 일으켜도 다른 DataNode에 존재하므로, 데이터 손실을 방지합니다.
  - **데이터 분산:** 복제 블록은 서로 다른 랙이나 데이터센터에 분산되어 저장되어, 물리적 장애에 대비합니다.
  
- **자동 복제 및 복구:**  
  NameNode는 주기적으로 DataNode로부터 보고받은 상태를 바탕으로, 복제 블록이 부족한 경우 자동으로 추가 복제를 명령합니다. 반대로, 장애가 발생한 DataNode의 블록은 재복제 과정을 통해 복원됩니다.

---

## 4. HDFS의 데이터 처리 경로

### 4.1. 쓰기 작업

1. **클라이언트가 파일 생성 요청을 보냄:**  
   클라이언트는 파일 생성 명령을 NameNode에 전송하고, NameNode는 파일의 메타데이터와 블록 배치를 결정합니다.
2. **데이터 블록 전송:**  
   클라이언트는 파일을 블록 단위로 분할한 후, 해당 블록을 지정된 DataNode들로 순차적으로 전송합니다.
3. **파이프라인 전송:**  
   복제 팩터에 따라 블록이 여러 DataNode로 파이프라인 방식으로 전송되어, 한 DataNode에서 블록을 받으면 다음 DataNode로 전송합니다.
4. **확인 및 완료:**  
   모든 DataNode가 블록을 저장하면, 클라이언트에 성공 응답을 반환합니다.

### 4.2. 읽기 작업

1. **클라이언트가 파일 읽기 요청을 보냄:**  
   클라이언트는 NameNode에 파일 읽기 요청을 보냅니다.
2. **블록 위치 조회:**  
   NameNode는 해당 파일의 블록 목록과 각 블록의 위치(저장된 DataNode)를 클라이언트에 전달합니다.
3. **DataNode에서 데이터 읽기:**  
   클라이언트는 가장 가까운(네트워크 지연이 적은) DataNode에서 직접 데이터 블록을 읽어옵니다.
4. **파일 조합:**  
   읽어온 블록들을 순서대로 조합하여 전체 파일을 클라이언트에 제공합니다.

---

## 5. 성능 최적화 및 관리 전략

### 5.1. 블록 크기 및 복제 팩터 조정

- **블록 크기:**  
  파일의 특성과 클러스터 환경에 따라 블록 크기를 조정하여, 메타데이터 오버헤드를 줄이고 데이터 처리 효율을 최적화합니다.
  
- **복제 팩터:**  
  데이터의 중요도와 가용성 요구 사항에 따라 복제 팩터를 조정하여, 안정성과 성능 간의 균형을 맞춥니다.

### 5.2. 클러스터 모니터링 및 유지보수

- **Nodetool 및 JMX 모니터링:**  
  `nodetool` 명령어와 JMX 기반 모니터링 도구를 활용하여, 각 노드의 상태, 디스크 사용량, 네트워크 트래픽, 읽기/쓰기 지연 등을 모니터링합니다.
  
- **Compaction 및 Garbage Collection:**  
  SSTable과 같은 하위 저장 파일의 정리를 통해 데이터 조각화를 최소화하고, 디스크 I/O 성능을 유지합니다.

### 5.3. 백업 및 복구 전략

- **스냅샷:**  
  정기적인 스냅샷을 통해 클러스터 상태를 백업하고, 장애 발생 시 빠르게 복구할 수 있도록 합니다.
  
- **데이터 복제 테스트:**  
  복제 및 재복제 기능이 정상적으로 작동하는지 주기적으로 테스트하여, 장애 상황에 대비합니다.

---

## 6. 활용 사례

### 6.1. 대규모 로그 저장 및 실시간 분석

- **웹 로그 분석:**  
  수십억 건의 웹 로그 데이터를 HDFS에 저장하고, MapReduce나 Spark와 같은 분산 처리 프레임워크를 활용하여 실시간 또는 배치 분석을 수행합니다.
  
- **IoT 센서 데이터:**  
  대량의 센서 데이터를 분산 저장하여, 시계열 분석 및 실시간 모니터링 시스템의 백엔드로 활용합니다.

### 6.2. 데이터 웨어하우징 및 빅데이터 처리

- **데이터 아카이빙:**  
  HDFS는 빅데이터 분석 플랫폼(Hadoop)의 핵심 스토리지 계층으로, 데이터 웨어하우스 구축 및 분석에 최적화되어 있습니다.
  
- **대규모 데이터 처리:**  
  수평적 확장성과 병렬 처리 기능을 활용하여, 대용량 데이터의 집계, 정제, 분석 작업을 효율적으로 수행합니다.

---

## 7. 결론

HDFS는 대규모 분산 파일시스템으로서, 높은 확장성, 내결함성, 그리고 병렬 처리 능력을 바탕으로 빅데이터 처리 및 분석에 필수적인 인프라입니다.

- **분산 아키텍처:**  
  NameNode와 DataNode로 구성된 피어 투 피어 구조를 통해, 데이터의 저장 및 접근 효율성을 극대화하고, 단일 장애점을 최소화합니다.
  
- **데이터 복제 및 블록 저장:**  
  파일을 일정 크기의 블록으로 분할하여 여러 노드에 복제 저장함으로써, 데이터 안정성과 고가용성을 보장합니다.
  
- **확장성과 성능 최적화:**  
  블록 크기, 복제 팩터, Compaction 등 다양한 설정과 유지보수 전략을 통해, 클러스터의 성능을 지속적으로 최적화할 수 있습니다.

HDFS는 실시간 로그 분석, IoT 데이터 수집, 데이터 웨어하우징 등 대규모 데이터 저장 및 처리 요구가 있는 환경에서 강력한 솔루션을 제공합니다.  
프로젝트 요구사항에 따라 적절한 데이터 모델링, 클러스터 구성, 모니터링 및 백업 전략을 종합적으로 고려하여 HDFS를 도입하면, 분산 환경에서 안정적이고 확장 가능한 데이터 처리 시스템을 구축할 수 있습니다.

---